{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_LIg-pkFyLU"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "71iBjs1fF9lN",
        "outputId": "6cfc5c15-7d5b-4165-9e35-210769206881"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f831ca1-fc40-43e4-855e-181fba9dc614\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7f831ca1-fc40-43e4-855e-181fba9dc614\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"lokadevm\",\"key\":\"460dc02f59f07c98338841eab1442586\"}'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Download your api kaggle.jdon from kaggle and upload it here\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_28NYb3GDPo",
        "outputId": "0fae1988-3859-426f-f92e-be5a0d4fbd18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okqdwuaIGI6A",
        "outputId": "79782f52-c33d-4409-da14-d461021a923b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading tuberculosis-tb-chest-xray-dataset.zip to /content\n",
            " 98% 649M/663M [00:07<00:00, 159MB/s]\n",
            "100% 663M/663M [00:07<00:00, 90.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d tawsifurrahman/tuberculosis-tb-chest-xray-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Tx4uISGRpV",
        "outputId": "15b7c9a9-48d0-491e-e9a3-4bb1abb88170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "#unziping the file\n",
        "from zipfile import ZipFile\n",
        "file_name = '/content/tuberculosis-tb-chest-xray-dataset.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdltcvjbGVAl",
        "outputId": "bcafcc1d-e56e-4977-b509-4f3f5f94605b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "! pip install split-folders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFgp8rLTGYtO",
        "outputId": "182d1663-0146-43ae-dec2-d59436c1f584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in the Train Dataset: 3360\n",
            "Number of samples in the Test Dataset: 840\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/TB_Chest_Radiography_Database'\n",
        "normal_dir = os.path.join(data_dir, 'Normal')\n",
        "tb_dir = os.path.join(data_dir, 'Tuberculosis')\n",
        "\n",
        "# Load images and labels\n",
        "normal_images = [os.path.join(normal_dir, img) for img in os.listdir(normal_dir)]\n",
        "tb_images = [os.path.join(tb_dir, img) for img in os.listdir(tb_dir)]\n",
        "images = normal_images + tb_images\n",
        "labels = [0] * len(normal_images) + [1] * len(tb_images)  # 0 for normal, 1 for tuberculosis\n",
        "\n",
        "# Resize and normalize images\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize to common size\n",
        "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Preprocess all images\n",
        "processed_images = [preprocess_image(img) for img in images]\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(processed_images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Count the number of samples in each dataset\n",
        "train_count = len(train_images)\n",
        "test_count = len(test_images)\n",
        "\n",
        "# Print the number of samples in each dataset\n",
        "print(\"Number of samples in the Train Dataset:\", train_count)\n",
        "print(\"Number of samples in the Test Dataset:\", test_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbhmVGH2bF3b",
        "outputId": "9fffd5a7-538a-4574-9e12-072ca60f29d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYoYO21KfDqi",
        "outputId": "d16f965c-60ed-4660-9059-b6489cc2114a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with learning rate: 0.001, dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.0293"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r105/105 [==============================] - 84s 478ms/step - loss: 0.5801 - accuracy: 0.0293 - val_loss: 0.5400 - val_accuracy: 0.0283\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 48s 454ms/step - loss: 0.5432 - accuracy: 0.0302 - val_loss: 0.5383 - val_accuracy: 0.0283\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 54s 516ms/step - loss: 0.5421 - accuracy: 0.0302 - val_loss: 0.5377 - val_accuracy: 0.0283\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 47s 451ms/step - loss: 0.5418 - accuracy: 0.0302 - val_loss: 0.5381 - val_accuracy: 0.0283\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 56s 530ms/step - loss: 0.5414 - accuracy: 0.0302 - val_loss: 0.5375 - val_accuracy: 0.0283\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 56s 531ms/step - loss: 0.5414 - accuracy: 0.0302 - val_loss: 0.5373 - val_accuracy: 0.0283\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 47s 450ms/step - loss: 0.5413 - accuracy: 0.0302 - val_loss: 0.5374 - val_accuracy: 0.0283\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 48s 453ms/step - loss: 0.5412 - accuracy: 0.0302 - val_loss: 0.5373 - val_accuracy: 0.0283\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 60s 570ms/step - loss: 0.5412 - accuracy: 0.0302 - val_loss: 0.5372 - val_accuracy: 0.0283\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 48s 456ms/step - loss: 0.5411 - accuracy: 0.0302 - val_loss: 0.5378 - val_accuracy: 0.0283\n",
            "27/27 [==============================] - 3s 104ms/step - loss: 0.5378 - accuracy: 0.0283\n",
            "Test accuracy for current configuration: 0.02833898551762104\n",
            "Training model with learning rate: 0.001, dropout rate: 0.7\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 65s 564ms/step - loss: 0.5701 - accuracy: 0.0297 - val_loss: 0.5391 - val_accuracy: 0.0283\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 68s 651ms/step - loss: 0.5469 - accuracy: 0.0302 - val_loss: 0.5381 - val_accuracy: 0.0283\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 64s 614ms/step - loss: 0.5456 - accuracy: 0.0302 - val_loss: 0.5377 - val_accuracy: 0.0283\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 57s 547ms/step - loss: 0.5453 - accuracy: 0.0302 - val_loss: 0.5375 - val_accuracy: 0.0283\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 58s 556ms/step - loss: 0.5451 - accuracy: 0.0302 - val_loss: 0.5374 - val_accuracy: 0.0283\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 46s 440ms/step - loss: 0.5453 - accuracy: 0.0302 - val_loss: 0.5397 - val_accuracy: 0.0283\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 46s 436ms/step - loss: 0.5454 - accuracy: 0.0302 - val_loss: 0.5376 - val_accuracy: 0.0283\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 46s 443ms/step - loss: 0.5450 - accuracy: 0.0302 - val_loss: 0.5375 - val_accuracy: 0.0283\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 47s 447ms/step - loss: 0.5447 - accuracy: 0.0302 - val_loss: 0.5375 - val_accuracy: 0.0283\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 66s 631ms/step - loss: 0.5446 - accuracy: 0.0302 - val_loss: 0.5373 - val_accuracy: 0.0283\n",
            "27/27 [==============================] - 3s 106ms/step - loss: 0.5373 - accuracy: 0.0283\n",
            "Test accuracy for current configuration: 0.02833898551762104\n",
            "Training model with learning rate: 0.0001, dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 66s 573ms/step - loss: 0.6096 - accuracy: 0.0291 - val_loss: 0.5490 - val_accuracy: 0.0283\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 61s 582ms/step - loss: 0.5510 - accuracy: 0.0301 - val_loss: 0.5424 - val_accuracy: 0.0283\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 61s 584ms/step - loss: 0.5461 - accuracy: 0.0302 - val_loss: 0.5402 - val_accuracy: 0.0283\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 59s 563ms/step - loss: 0.5445 - accuracy: 0.0302 - val_loss: 0.5393 - val_accuracy: 0.0283\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 59s 567ms/step - loss: 0.5437 - accuracy: 0.0302 - val_loss: 0.5387 - val_accuracy: 0.0283\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 62s 588ms/step - loss: 0.5432 - accuracy: 0.0302 - val_loss: 0.5384 - val_accuracy: 0.0283\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 56s 536ms/step - loss: 0.5430 - accuracy: 0.0302 - val_loss: 0.5384 - val_accuracy: 0.0283\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 60s 570ms/step - loss: 0.5425 - accuracy: 0.0302 - val_loss: 0.5380 - val_accuracy: 0.0283\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 55s 524ms/step - loss: 0.5423 - accuracy: 0.0302 - val_loss: 0.5378 - val_accuracy: 0.0283\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 57s 540ms/step - loss: 0.5421 - accuracy: 0.0302 - val_loss: 0.5378 - val_accuracy: 0.0283\n",
            "27/27 [==============================] - 3s 107ms/step - loss: 0.5378 - accuracy: 0.0283\n",
            "Test accuracy for current configuration: 0.02833898551762104\n",
            "Training model with learning rate: 0.0001, dropout rate: 0.7\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 71s 617ms/step - loss: 0.6106 - accuracy: 0.0271 - val_loss: 0.5493 - val_accuracy: 0.0283\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 59s 559ms/step - loss: 0.5542 - accuracy: 0.0301 - val_loss: 0.5414 - val_accuracy: 0.0283\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 59s 565ms/step - loss: 0.5497 - accuracy: 0.0302 - val_loss: 0.5397 - val_accuracy: 0.0283\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 50s 474ms/step - loss: 0.5485 - accuracy: 0.0302 - val_loss: 0.5392 - val_accuracy: 0.0283\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 78s 749ms/step - loss: 0.5475 - accuracy: 0.0302 - val_loss: 0.5392 - val_accuracy: 0.0283\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 48s 457ms/step - loss: 0.5470 - accuracy: 0.0302 - val_loss: 0.5401 - val_accuracy: 0.0283\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 63s 600ms/step - loss: 0.5466 - accuracy: 0.0302 - val_loss: 0.5383 - val_accuracy: 0.0283\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 51s 484ms/step - loss: 0.5464 - accuracy: 0.0302 - val_loss: 0.5386 - val_accuracy: 0.0283\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 68s 648ms/step - loss: 0.5463 - accuracy: 0.0302 - val_loss: 0.5380 - val_accuracy: 0.0283\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 50s 474ms/step - loss: 0.5460 - accuracy: 0.0302 - val_loss: 0.5385 - val_accuracy: 0.0283\n",
            "27/27 [==============================] - 3s 109ms/step - loss: 0.5385 - accuracy: 0.0283\n",
            "Test accuracy for current configuration: 0.02833898551762104\n",
            "Hyperparameter tuning completed.\n",
            "Best test accuracy: 0.02833898551762104\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/TB_Chest_Radiography_Database'\n",
        "normal_dir = os.path.join(data_dir, 'Normal')\n",
        "tb_dir = os.path.join(data_dir, 'Tuberculosis')\n",
        "\n",
        "# Load images and labels\n",
        "normal_images = [os.path.join(normal_dir, img) for img in os.listdir(normal_dir)]\n",
        "tb_images = [os.path.join(tb_dir, img) for img in os.listdir(tb_dir)]\n",
        "images = normal_images + tb_images\n",
        "labels = [0] * len(normal_images) + [1] * len(tb_images)  # 0 for normal, 1 for tuberculosis\n",
        "\n",
        "# Resize and normalize images\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (128, 128))  # Resize to common size\n",
        "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Preprocess all images\n",
        "processed_images = [preprocess_image(img) for img in images]\n",
        "processed_images = np.expand_dims(processed_images, axis=-1)  # Expand dimensions to add channel\n",
        "\n",
        "# Convert labels to the same shape as the images for segmentation\n",
        "processed_labels = [preprocess_image(img) for img in images]\n",
        "processed_labels = np.expand_dims(processed_labels, axis=-1)  # Expand dimensions to add channel\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(processed_images, processed_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(BATCH_SIZE)\n",
        "\n",
        "# Define U-Net model architecture\n",
        "def unet_model(input_shape, dropout_rate=0.5):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    c9 = layers.Dropout(dropout_rate)(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (128, 128, 1)\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "learning_rates = [0.001, 0.0001]\n",
        "dropout_rates = [0.5, 0.7]\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "early_stopping_patience = 5  # Adjusted early stopping patience\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "for learning_rate in learning_rates:\n",
        "    for dropout_rate in dropout_rates:\n",
        "        print(f\"Training model with learning rate: {learning_rate}, dropout rate: {dropout_rate}\")\n",
        "\n",
        "        # Create the U-Net model\n",
        "        model = unet_model(input_shape, dropout_rate)\n",
        "\n",
        "        # Compile the model\n",
        "        optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Define callbacks\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
        "        model_checkpoint = ModelCheckpoint(filepath='unet_best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size,\n",
        "                            validation_data=test_dataset, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "        # Evaluate the model\n",
        "        test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "        print(f\"Test accuracy for current configuration: {test_accuracy}\")\n",
        "\n",
        "        # Check if current model is the best so far\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_model = model\n",
        "\n",
        "print(\"Hyperparameter tuning completed.\")\n",
        "print(f\"Best test accuracy: {best_accuracy}\")\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('best_unet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "SWpHASuLM7gO",
        "outputId": "bf661be8-6b62-4aa8-f18d-64dc2e44df12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 3s 112ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "unknown is not supported",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f59b370c591a>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Calculate the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Calculate performance metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown is not supported"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/TB_Chest_Radiography_Database'\n",
        "normal_dir = os.path.join(data_dir, 'Normal')\n",
        "tb_dir = os.path.join(data_dir, 'Tuberculosis')\n",
        "\n",
        "# Load images and labels\n",
        "normal_images = [os.path.join(normal_dir, img) for img in os.listdir(normal_dir)]\n",
        "tb_images = [os.path.join(tb_dir, img) for img in os.listdir(tb_dir)]\n",
        "images = normal_images + tb_images\n",
        "labels = [0] * len(normal_images) + [1] * len(tb_images)  # 0 for normal, 1 for tuberculosis\n",
        "\n",
        "# Resize and normalize images\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (128, 128))  # Resize to common size\n",
        "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Preprocess all images\n",
        "processed_images = [preprocess_image(img) for img in images]\n",
        "processed_images = np.expand_dims(processed_images, axis=-1)  # Expand dimensions to add channel\n",
        "\n",
        "# Convert labels to the same shape as the images for segmentation\n",
        "processed_labels = [preprocess_image(img) for img in images]\n",
        "processed_labels = np.expand_dims(processed_labels, axis=-1)  # Expand dimensions to add channel\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(processed_images, processed_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(BATCH_SIZE)\n",
        "\n",
        "# Load the best model\n",
        "best_model = models.load_model('best_unet_model.h5')\n",
        "\n",
        "# Predict on the test dataset\n",
        "y_pred_prob = best_model.predict(test_dataset)\n",
        "y_pred = np.where(y_pred_prob > 0.5, 1, 0)  # Threshold probabilities to get binary predictions\n",
        "\n",
        "# Get true labels\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = np.trace(cm) / np.sum(cm)\n",
        "precision = cm[1, 1] / np.sum(cm[:, 1])\n",
        "recall = cm[1, 1] / np.sum(cm[1, :])\n",
        "sensitivity = recall\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "\n",
        "# Generate a heatmap for the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Tuberculosis\"], yticklabels=[\"Normal\", \"Tuberculosis\"])\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Tuberculosis\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYTIMdzcVv64",
        "outputId": "98855ec3-c8b2-4bff-dfd9-371555c8fc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with learning rate: 0.001, dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "  5/105 [>.............................] - ETA: 1:50:33 - loss: 0.3988 - dice_coefficient: 0.6012"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/TB_Chest_Radiography_Database'\n",
        "normal_dir = os.path.join(data_dir, 'Normal')\n",
        "tb_dir = os.path.join(data_dir, 'Tuberculosis')\n",
        "\n",
        "# Load images and labels\n",
        "normal_images = [os.path.join(normal_dir, img) for img in os.listdir(normal_dir)]\n",
        "tb_images = [os.path.join(tb_dir, img) for img in os.listdir(tb_dir)]\n",
        "images = normal_images + tb_images\n",
        "labels = [0] * len(normal_images) + [1] * len(tb_images)  # 0 for normal, 1 for tuberculosis\n",
        "\n",
        "# Resize and normalize images\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (128, 128))  # Resize to common size\n",
        "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Preprocess all images\n",
        "processed_images = [preprocess_image(img) for img in images]\n",
        "processed_images = np.expand_dims(processed_images, axis=-1)  # Expand dimensions to add channel\n",
        "\n",
        "# Convert labels to the same shape as the images for segmentation\n",
        "processed_labels = [preprocess_image(img) for img in images]\n",
        "processed_labels = np.expand_dims(processed_labels, axis=-1)  # Expand dimensions to add channel\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(processed_images, processed_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(BATCH_SIZE)\n",
        "\n",
        "# Define U-Net model architecture\n",
        "def unet_model(input_shape, dropout_rate=0.5):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    c9 = layers.Dropout(dropout_rate)(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (128, 128, 1)\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "learning_rates = [0.001, 0.0001]\n",
        "dropout_rates = [0.5, 0.7]\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "early_stopping_patience = 5  # Adjusted early stopping patience\n",
        "\n",
        "# Define dice loss\n",
        "def dice_loss(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "    return 1 - (numerator + 1) / (denominator + 1)\n",
        "\n",
        "# Define dice coefficient\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "    return (numerator + 1) / (denominator + 1)\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "for learning_rate in learning_rates:\n",
        "    for dropout_rate in dropout_rates:\n",
        "        print(f\"Training model with learning rate: {learning_rate}, dropout rate: {dropout_rate}\")\n",
        "\n",
        "        # Create the U-Net model\n",
        "        model = unet_model(input_shape, dropout_rate)\n",
        "\n",
        "        # Compile the model\n",
        "        optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "        model.compile(optimizer=optimizer, loss=dice_loss, metrics=[dice_coefficient])\n",
        "\n",
        "        # Define callbacks\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
        "        model_checkpoint = ModelCheckpoint(filepath='unet_best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size,\n",
        "                            validation_data=test_dataset, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "        # Evaluate the model\n",
        "        test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "        print(f\"Test accuracy for current configuration: {test_accuracy}\")\n",
        "\n",
        "        # Check if current model is the best so far\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_model = model\n",
        "\n",
        "print(\"Hyperparameter tuning completed.\")\n",
        "print(f\"Best test accuracy: {best_accuracy}\")\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('best_unet_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FxRwV5e9b2h3",
        "outputId": "107d8502-91a0-456a-8043-86b6c3d2b314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with learning rate: 0.001, dropout rate: 0.5\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node gradient_tape/mean_squared_error/BroadcastGradientArgs defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-1-74f409498546>\", line 150, in <cell line: 130>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nIncompatible shapes: [32,9441,4] vs. [32]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_31873]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-74f409498546>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size,\n\u001b[0m\u001b[1;32m    151\u001b[0m                             validation_data=test_dataset, callbacks=[early_stopping, model_checkpoint])\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/mean_squared_error/BroadcastGradientArgs defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-1-74f409498546>\", line 150, in <cell line: 130>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nIncompatible shapes: [32,9441,4] vs. [32]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_31873]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/TB_Chest_Radiography_Database'\n",
        "normal_dir = os.path.join(data_dir, 'Normal')\n",
        "tb_dir = os.path.join(data_dir, 'Tuberculosis')\n",
        "\n",
        "# Load images and labels\n",
        "normal_images = [os.path.join(normal_dir, img) for img in os.listdir(normal_dir)]\n",
        "tb_images = [os.path.join(tb_dir, img) for img in os.listdir(tb_dir)]\n",
        "images = normal_images + tb_images\n",
        "labels = [0] * len(normal_images) + [1] * len(tb_images)  # 0 for normal, 1 for tuberculosis\n",
        "\n",
        "# Resize and normalize images\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize to common size\n",
        "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Preprocess all images\n",
        "processed_images = [preprocess_image(img) for img in images]\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(processed_images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow tensors and ensure labels are float32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Define Focal Loss\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "\n",
        "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        fl = -alpha_t * tf.pow((1 - p_t), gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))\n",
        "        return tf.reduce_sum(fl, axis=-1)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "# Build Feature Pyramid Network\n",
        "def build_fpn(backbone):\n",
        "    c3_output = backbone.get_layer(\"conv3_block4_out\").output\n",
        "    c4_output = backbone.get_layer(\"conv4_block6_out\").output\n",
        "    c5_output = backbone.get_layer(\"conv5_block3_out\").output\n",
        "\n",
        "    p5_output = layers.Conv2D(256, (1, 1), padding=\"same\", name=\"fpn_p5\")(c5_output)\n",
        "    p4_output = layers.Add(name=\"fpn_p4\")([\n",
        "        layers.UpSampling2D(size=(2, 2), name=\"fpn_p5upsampled\")(p5_output),\n",
        "        layers.Conv2D(256, (1, 1), padding=\"same\", name=\"fpn_c4p4\")(c4_output)\n",
        "    ])\n",
        "    p3_output = layers.Add(name=\"fpn_p3\")([\n",
        "        layers.UpSampling2D(size=(2, 2), name=\"fpn_p4upsampled\")(p4_output),\n",
        "        layers.Conv2D(256, (1, 1), padding=\"same\", name=\"fpn_c3p3\")(c3_output)\n",
        "    ])\n",
        "    p6_output = layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\", name=\"fpn_p6\")(p5_output)\n",
        "    p7_output = layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\", name=\"fpn_p7\")(tf.nn.relu(p6_output))\n",
        "\n",
        "    return [p3_output, p4_output, p5_output, p6_output, p7_output]\n",
        "\n",
        "# Build Classification Subnet\n",
        "def build_classification_subnet(num_classes, num_anchors):\n",
        "    inputs = layers.Input(shape=(None, None, 256))\n",
        "    x = inputs\n",
        "    for _ in range(4):\n",
        "        x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(num_classes * num_anchors, (3, 3), padding=\"same\", activation=\"sigmoid\")(x)\n",
        "    outputs = layers.Reshape((-1, num_classes))(x)\n",
        "    return models.Model(inputs=inputs, outputs=outputs, name=\"classification_subnet\")\n",
        "\n",
        "# Build Regression Subnet\n",
        "def build_regression_subnet(num_anchors):\n",
        "    inputs = layers.Input(shape=(None, None, 256))\n",
        "    x = inputs\n",
        "    for _ in range(4):\n",
        "        x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(num_anchors * 4, (3, 3), padding=\"same\")(x)\n",
        "    outputs = layers.Reshape((-1, 4))(x)\n",
        "    return models.Model(inputs=inputs, outputs=outputs, name=\"regression_subnet\")\n",
        "\n",
        "# Create RetinaNet Model\n",
        "def create_retinanet(input_shape, num_classes, num_anchors):\n",
        "    backbone = ResNet50(include_top=False, input_shape=input_shape)\n",
        "    backbone.trainable = True\n",
        "\n",
        "    pyramid_features = build_fpn(backbone)\n",
        "    classification_subnet = build_classification_subnet(num_classes, num_anchors)\n",
        "    regression_subnet = build_regression_subnet(num_anchors)\n",
        "\n",
        "    inputs = backbone.input\n",
        "    classification_outputs = [classification_subnet(feature) for feature in pyramid_features]\n",
        "    regression_outputs = [regression_subnet(feature) for feature in pyramid_features]\n",
        "\n",
        "    classification_output = layers.Concatenate(axis=1, name=\"classification_output\")(classification_outputs)\n",
        "    regression_output = layers.Concatenate(axis=1, name=\"regression_output\")(regression_outputs)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=[classification_output, regression_output])\n",
        "    return model\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2  # 2 classes: Normal and Tuberculosis\n",
        "num_anchors = 9  # Number of anchors per feature map location\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "learning_rates = [0.001, 0.0001]\n",
        "dropout_rates = [0.5, 0.7]\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "early_stopping_patience = 5  # Adjusted early stopping patience\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "for learning_rate in learning_rates:\n",
        "    for dropout_rate in dropout_rates:\n",
        "        print(f\"Training model with learning rate: {learning_rate}, dropout rate: {dropout_rate}\")\n",
        "\n",
        "        # Create the RetinaNet model\n",
        "        model = create_retinanet(input_shape, num_classes, num_anchors)\n",
        "\n",
        "        # Compile the model\n",
        "        optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss={'classification_output': focal_loss(), 'regression_output': 'mse'},\n",
        "            metrics={'classification_output': 'accuracy'}\n",
        "        )\n",
        "\n",
        "        # Define callbacks\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
        "        model_checkpoint = ModelCheckpoint(filepath='retinanet_best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size,\n",
        "                            validation_data=test_dataset, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "        # Evaluate the model\n",
        "        _, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "        print(f\"Test accuracy for current configuration: {test_accuracy}\")\n",
        "\n",
        "        # Check if current model is the best so far\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_model = model\n",
        "\n",
        "print(\"Hyperparameter tuning completed.\")\n",
        "print(f\"Best test accuracy: {best_accuracy}\")\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('best_retinanet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36dyLl-Hjp_5",
        "outputId": "1727a6ec-1a93-4018-f35d-601084fd281f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with learning rate: 0.001, dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.9021"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "105/105 [==============================] - 178s 2s/step - loss: 0.2458 - accuracy: 0.9021 - val_loss: 1.1338 - val_accuracy: 0.1631\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.1319 - accuracy: 0.9527 - val_loss: 3.6847 - val_accuracy: 0.1631\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.0838 - accuracy: 0.9720 - val_loss: 4.1123 - val_accuracy: 0.1631\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.0720 - accuracy: 0.9747 - val_loss: 5.1562 - val_accuracy: 0.1631\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0581 - accuracy: 0.9824 - val_loss: 4.6041 - val_accuracy: 0.1667\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.1779 - val_accuracy: 0.9381\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.3198 - val_accuracy: 0.9345\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.0360 - accuracy: 0.9893 - val_loss: 2.5331 - val_accuracy: 0.3821\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 15.5199 - val_accuracy: 0.1702\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 3.3034 - val_accuracy: 0.5976\n",
            "27/27 [==============================] - 7s 247ms/step - loss: 3.3034 - accuracy: 0.5976\n",
            "Test accuracy for current configuration: 0.5976190567016602\n",
            "Training model with learning rate: 0.001, dropout rate: 0.7\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 173s 2s/step - loss: 0.2623 - accuracy: 0.9071 - val_loss: 2.2469 - val_accuracy: 0.1631\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.1621 - accuracy: 0.9470 - val_loss: 3.1168 - val_accuracy: 0.1631\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0921 - accuracy: 0.9682 - val_loss: 3.4020 - val_accuracy: 0.1631\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0939 - accuracy: 0.9664 - val_loss: 2.9071 - val_accuracy: 0.1643\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 2.9796 - val_accuracy: 0.2655\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.0558 - accuracy: 0.9804 - val_loss: 3.3810 - val_accuracy: 0.3619\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 2.2469 - accuracy: 0.1631\n",
            "Test accuracy for current configuration: 0.16309523582458496\n",
            "Training model with learning rate: 0.0001, dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 175s 2s/step - loss: 0.4112 - accuracy: 0.8238 - val_loss: 0.6283 - val_accuracy: 0.8369\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.2430 - accuracy: 0.9137 - val_loss: 0.6453 - val_accuracy: 0.8369\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.1871 - accuracy: 0.9327 - val_loss: 0.7916 - val_accuracy: 0.1714\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 156s 1s/step - loss: 0.1680 - accuracy: 0.9405 - val_loss: 1.4796 - val_accuracy: 0.1631\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.1317 - accuracy: 0.9515 - val_loss: 0.4319 - val_accuracy: 0.8155\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.1094 - accuracy: 0.9613 - val_loss: 1.0111 - val_accuracy: 0.5512\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.1127 - accuracy: 0.9595 - val_loss: 1.1623 - val_accuracy: 0.5595\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.1131 - accuracy: 0.9598 - val_loss: 0.2303 - val_accuracy: 0.9202\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.0978 - accuracy: 0.9682 - val_loss: 0.4142 - val_accuracy: 0.8643\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.0816 - accuracy: 0.9738 - val_loss: 0.1089 - val_accuracy: 0.9595\n",
            "27/27 [==============================] - 9s 328ms/step - loss: 0.1089 - accuracy: 0.9595\n",
            "Test accuracy for current configuration: 0.9595237970352173\n",
            "Training model with learning rate: 0.0001, dropout rate: 0.7\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 174s 2s/step - loss: 0.6208 - accuracy: 0.7161 - val_loss: 0.6012 - val_accuracy: 0.8369\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.2501 - accuracy: 0.9167 - val_loss: 0.6791 - val_accuracy: 0.7250\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.2103 - accuracy: 0.9250 - val_loss: 0.6224 - val_accuracy: 0.7952\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.1771 - accuracy: 0.9381 - val_loss: 0.5684 - val_accuracy: 0.7488\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.1630 - accuracy: 0.9438 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.1391 - accuracy: 0.9479 - val_loss: 0.4404 - val_accuracy: 0.7857\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 155s 1s/step - loss: 0.1193 - accuracy: 0.9580 - val_loss: 0.1244 - val_accuracy: 0.9560\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 163s 2s/step - loss: 0.1045 - accuracy: 0.9622 - val_loss: 0.1000 - val_accuracy: 0.9679\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 155s 1s/step - loss: 0.0966 - accuracy: 0.9646 - val_loss: 0.2147 - val_accuracy: 0.9524\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 156s 1s/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.0823 - val_accuracy: 0.9714\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0823 - accuracy: 0.9714\n",
            "Test accuracy for current configuration: 0.9714285731315613\n",
            "Hyperparameter tuning completed.\n",
            "Best test accuracy: 0.9714285731315613\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/TB_Chest_Radiography_Database'\n",
        "normal_dir = os.path.join(data_dir, 'Normal')\n",
        "tb_dir = os.path.join(data_dir, 'Tuberculosis')\n",
        "\n",
        "# Load images and labels\n",
        "normal_images = [os.path.join(normal_dir, img) for img in os.listdir(normal_dir)]\n",
        "tb_images = [os.path.join(tb_dir, img) for img in os.listdir(tb_dir)]\n",
        "images = normal_images + tb_images\n",
        "labels = [0] * len(normal_images) + [1] * len(tb_images)  # 0 for normal, 1 for tuberculosis\n",
        "\n",
        "# Resize and normalize images\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize to common size\n",
        "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Preprocess all images\n",
        "processed_images = [preprocess_image(img) for img in images]\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(processed_images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# GhostNet block\n",
        "def ghost_module(x, out_channels, ratio=2, dw_size=3, strides=1, activation=True):\n",
        "    init_channels = int(np.ceil(out_channels / ratio))\n",
        "    new_channels = int(init_channels * (ratio - 1))\n",
        "\n",
        "    primary_conv = layers.Conv2D(init_channels, 1, strides=strides, padding='same', use_bias=False)(x)\n",
        "    primary_conv = layers.BatchNormalization()(primary_conv)\n",
        "    if activation:\n",
        "        primary_conv = layers.ReLU()(primary_conv)\n",
        "\n",
        "    cheap_operation = layers.DepthwiseConv2D(dw_size, 1, padding='same', use_bias=False)(primary_conv)\n",
        "    cheap_operation = layers.BatchNormalization()(cheap_operation)\n",
        "    if activation:\n",
        "        cheap_operation = layers.ReLU()(cheap_operation)\n",
        "\n",
        "    out = layers.Concatenate(axis=-1)([primary_conv, cheap_operation])\n",
        "    out = layers.Conv2D(out_channels, 1, padding='same', use_bias=False)(out)\n",
        "    out = layers.BatchNormalization()(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "# GhostNet model\n",
        "def create_ghostnet(input_shape, num_classes, learning_rate=0.001, dropout_rate=0.5):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(16, 3, 2, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = ghost_module(x, 16)\n",
        "    x = ghost_module(x, 24, strides=2)\n",
        "    x = ghost_module(x, 24)\n",
        "\n",
        "    x = ghost_module(x, 40, strides=2)\n",
        "    x = ghost_module(x, 40)\n",
        "\n",
        "    x = ghost_module(x, 80, strides=2)\n",
        "    x = ghost_module(x, 80)\n",
        "    x = ghost_module(x, 80)\n",
        "    x = ghost_module(x, 80)\n",
        "\n",
        "    x = ghost_module(x, 160, strides=2)\n",
        "    x = ghost_module(x, 160)\n",
        "\n",
        "    x = ghost_module(x, 320, strides=1)\n",
        "    x = layers.Conv2D(1280, 1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2  # 2 classes: Normal and Tuberculosis\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "learning_rates = [0.001, 0.0001]\n",
        "dropout_rates = [0.5, 0.7]\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "early_stopping_patience = 5  # Adjusted early stopping patience\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "for learning_rate in learning_rates:\n",
        "    for dropout_rate in dropout_rates:\n",
        "        print(f\"Training model with learning rate: {learning_rate}, dropout rate: {dropout_rate}\")\n",
        "\n",
        "        # Create the GhostNet model\n",
        "        model = create_ghostnet(input_shape, num_classes, learning_rate, dropout_rate)\n",
        "\n",
        "        # Define callbacks\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
        "        model_checkpoint = ModelCheckpoint(filepath='ghostnet_best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size,\n",
        "                            validation_data=test_dataset, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "        # Evaluate the model\n",
        "        _, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "        print(f\"Test accuracy for current configuration: {test_accuracy}\")\n",
        "\n",
        "        # Check if current model is the best so far\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_model = model\n",
        "\n",
        "print(\"Hyperparameter tuning completed.\")\n",
        "print(f\"Best test accuracy: {best_accuracy}\")\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('best_ghostnet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "lJFY3jqrmFTD",
        "outputId": "e9dbd084-d932-4d24-b83c-c8268fdf1432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 26s 737ms/step\n",
            "Accuracy: 0.9714285714285714\n",
            "Precision: 0.9312977099236641\n",
            "Recall: 0.8905109489051095\n",
            "Sensitivity: 0.8905109489051095\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.98      0.99      0.98       703\n",
            "Tuberculosis       0.93      0.89      0.91       137\n",
            "\n",
            "    accuracy                           0.97       840\n",
            "   macro avg       0.96      0.94      0.95       840\n",
            "weighted avg       0.97      0.97      0.97       840\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best model\n",
        "best_model = load_model('best_ghostnet_model.h5')\n",
        "\n",
        "# Predict on the test dataset\n",
        "y_pred = np.argmax(best_model.predict(test_dataset), axis=-1)\n",
        "\n",
        "# Get true labels\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = np.trace(cm) / np.sum(cm)\n",
        "precision = cm[1, 1] / np.sum(cm[:, 1])\n",
        "recall = cm[1, 1] / np.sum(cm[1, :])\n",
        "sensitivity = recall\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "\n",
        "# Generate a heatmap for the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Tuberculosis\"], yticklabels=[\"Normal\", \"Tuberculosis\"])\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Tuberculosis\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztSpWqvDrpLl",
        "outputId": "1aae2ab2-09ea-41bf-877f-f04fc7de657e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with learning rate: 0.001, dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.9071"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r105/105 [==============================] - 179s 2s/step - loss: 0.2467 - accuracy: 0.9071 - val_loss: 1.1172 - val_accuracy: 0.1631\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.1183 - accuracy: 0.9568 - val_loss: 1.7721 - val_accuracy: 0.1631\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.1013 - accuracy: 0.9625 - val_loss: 2.5051 - val_accuracy: 0.1631\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 174s 2s/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 2.8837 - val_accuracy: 0.1631\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.0568 - accuracy: 0.9774 - val_loss: 3.3586 - val_accuracy: 0.2179\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 0.2633 - val_accuracy: 0.8988\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 162s 2s/step - loss: 0.0445 - accuracy: 0.9830 - val_loss: 0.1246 - val_accuracy: 0.9524\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0467 - accuracy: 0.9812 - val_loss: 0.0716 - val_accuracy: 0.9750\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.0277 - accuracy: 0.9890 - val_loss: 0.0838 - val_accuracy: 0.9726\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.5348 - val_accuracy: 0.9417\n",
            "27/27 [==============================] - 9s 326ms/step - loss: 0.5348 - accuracy: 0.9417\n",
            "Test accuracy for current configuration: 0.9416666626930237\n",
            "Training model with learning rate: 0.001, dropout rate: 0.7\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 173s 2s/step - loss: 0.2979 - accuracy: 0.8863 - val_loss: 0.9585 - val_accuracy: 0.1631\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 165s 2s/step - loss: 0.1425 - accuracy: 0.9565 - val_loss: 1.9605 - val_accuracy: 0.1631\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 181s 2s/step - loss: 0.1008 - accuracy: 0.9664 - val_loss: 5.1162 - val_accuracy: 0.1631\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.0691 - accuracy: 0.9738 - val_loss: 6.1227 - val_accuracy: 0.1631\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.0649 - accuracy: 0.9771 - val_loss: 2.4175 - val_accuracy: 0.2798\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.3309 - val_accuracy: 0.8726\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 1.8226 - val_accuracy: 0.6619\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0583 - accuracy: 0.9786 - val_loss: 0.6933 - val_accuracy: 0.9083\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.0665 - accuracy: 0.9747 - val_loss: 0.7039 - val_accuracy: 0.7643\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 162s 2s/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 0.0620 - val_accuracy: 0.9762\n",
            "27/27 [==============================] - 7s 255ms/step - loss: 0.0620 - accuracy: 0.9762\n",
            "Test accuracy for current configuration: 0.976190447807312\n",
            "Training model with learning rate: 0.0001, dropout rate: 0.5\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 174s 2s/step - loss: 0.3797 - accuracy: 0.8565 - val_loss: 0.6417 - val_accuracy: 0.8369\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.2369 - accuracy: 0.9152 - val_loss: 0.5575 - val_accuracy: 0.8369\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.1843 - accuracy: 0.9336 - val_loss: 0.5011 - val_accuracy: 0.8369\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.1492 - accuracy: 0.9438 - val_loss: 1.1922 - val_accuracy: 0.1917\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.1119 - accuracy: 0.9589 - val_loss: 1.2564 - val_accuracy: 0.2845\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 163s 2s/step - loss: 0.1100 - accuracy: 0.9640 - val_loss: 0.2629 - val_accuracy: 0.9060\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 157s 1s/step - loss: 0.0875 - accuracy: 0.9688 - val_loss: 0.0771 - val_accuracy: 0.9762\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 0.4681 - val_accuracy: 0.8274\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 162s 2s/step - loss: 0.0647 - accuracy: 0.9759 - val_loss: 0.1658 - val_accuracy: 0.9512\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.0645 - accuracy: 0.9768 - val_loss: 0.0746 - val_accuracy: 0.9726\n",
            "27/27 [==============================] - 9s 328ms/step - loss: 0.0746 - accuracy: 0.9726\n",
            "Test accuracy for current configuration: 0.9726190567016602\n",
            "Training model with learning rate: 0.0001, dropout rate: 0.7\n",
            "Epoch 1/10\n",
            "105/105 [==============================] - 174s 2s/step - loss: 0.4216 - accuracy: 0.8515 - val_loss: 0.4777 - val_accuracy: 0.8369\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 162s 2s/step - loss: 0.2483 - accuracy: 0.9012 - val_loss: 0.4537 - val_accuracy: 0.8369\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 157s 2s/step - loss: 0.1854 - accuracy: 0.9220 - val_loss: 0.4505 - val_accuracy: 0.8369\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.1618 - accuracy: 0.9408 - val_loss: 2.2883 - val_accuracy: 0.1631\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 159s 2s/step - loss: 0.1317 - accuracy: 0.9491 - val_loss: 3.1432 - val_accuracy: 0.1560\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 161s 2s/step - loss: 0.1123 - accuracy: 0.9598 - val_loss: 0.4217 - val_accuracy: 0.8250\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0962 - accuracy: 0.9679 - val_loss: 0.0917 - val_accuracy: 0.9679\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 158s 2s/step - loss: 0.0919 - accuracy: 0.9673 - val_loss: 0.1942 - val_accuracy: 0.9226\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 160s 2s/step - loss: 0.0882 - accuracy: 0.9705 - val_loss: 0.3521 - val_accuracy: 0.8429\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 162s 2s/step - loss: 0.0726 - accuracy: 0.9723 - val_loss: 0.0635 - val_accuracy: 0.9798\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0635 - accuracy: 0.9798\n",
            "Test accuracy for current configuration: 0.9797618985176086\n",
            "Hyperparameter tuning completed.\n",
            "Best test accuracy: 0.9797618985176086\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/TB_Chest_Radiography_Database'\n",
        "normal_dir = os.path.join(data_dir, 'Normal')\n",
        "tb_dir = os.path.join(data_dir, 'Tuberculosis')\n",
        "\n",
        "# Load images and labels\n",
        "normal_images = [os.path.join(normal_dir, img) for img in os.listdir(normal_dir)]\n",
        "tb_images = [os.path.join(tb_dir, img) for img in os.listdir(tb_dir)]\n",
        "images = normal_images + tb_images\n",
        "labels = [0] * len(normal_images) + [1] * len(tb_images)  # 0 for normal, 1 for tuberculosis\n",
        "\n",
        "# Resize and normalize images\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize to common size\n",
        "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "\n",
        "# Preprocess all images\n",
        "processed_images = [preprocess_image(img) for img in images]\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(processed_images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# GhostNet block\n",
        "def ghost_module(x, out_channels, ratio=2, dw_size=3, strides=1, activation=True):\n",
        "    init_channels = int(np.ceil(out_channels / ratio))\n",
        "    new_channels = int(init_channels * (ratio - 1))\n",
        "\n",
        "    primary_conv = layers.Conv2D(init_channels, 1, strides=strides, padding='same', use_bias=False)(x)\n",
        "    primary_conv = layers.BatchNormalization()(primary_conv)\n",
        "    if activation:\n",
        "        primary_conv = layers.ReLU()(primary_conv)\n",
        "\n",
        "    cheap_operation = layers.DepthwiseConv2D(dw_size, 1, padding='same', use_bias=False)(primary_conv)\n",
        "    cheap_operation = layers.BatchNormalization()(cheap_operation)\n",
        "    if activation:\n",
        "        cheap_operation = layers.ReLU()(cheap_operation)\n",
        "\n",
        "    out = layers.Concatenate(axis=-1)([primary_conv, cheap_operation])\n",
        "    out = layers.Conv2D(out_channels, 1, padding='same', use_bias=False)(out)\n",
        "    out = layers.BatchNormalization()(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "# GhostNet model\n",
        "def create_ghostnet(input_shape, num_classes, learning_rate=0.001, dropout_rate=0.5):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(16, 3, 2, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = ghost_module(x, 16)\n",
        "    x = ghost_module(x, 24, strides=2)\n",
        "    x = ghost_module(x, 24)\n",
        "\n",
        "    x = ghost_module(x, 40, strides=2)\n",
        "    x = ghost_module(x, 40)\n",
        "\n",
        "    x = ghost_module(x, 80, strides=2)\n",
        "    x = ghost_module(x, 80)\n",
        "    x = ghost_module(x, 80)\n",
        "    x = ghost_module(x, 80)\n",
        "\n",
        "    x = ghost_module(x, 160, strides=2)\n",
        "    x = ghost_module(x, 160)\n",
        "\n",
        "    x = ghost_module(x, 320, strides=1)\n",
        "    x = layers.Conv2D(1280, 1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2  # 2 classes: Normal and Tuberculosis\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "learning_rates = [0.001, 0.0001]\n",
        "dropout_rates = [0.5, 0.7]\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "early_stopping_patience = 5  # Adjusted early stopping patience\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "for learning_rate in learning_rates:\n",
        "    for dropout_rate in dropout_rates:\n",
        "        print(f\"Training model with learning rate: {learning_rate}, dropout rate: {dropout_rate}\")\n",
        "\n",
        "        # Create the GhostNet model\n",
        "        model = create_ghostnet(input_shape, num_classes, learning_rate, dropout_rate)\n",
        "\n",
        "        # Define callbacks\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
        "        model_checkpoint = ModelCheckpoint(filepath='ghostnet_best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(train_dataset, epochs=epochs, batch_size=batch_size,\n",
        "                            validation_data=test_dataset, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "        # Evaluate the model\n",
        "        _, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "        print(f\"Test accuracy for current configuration: {test_accuracy}\")\n",
        "\n",
        "        # Check if current model is the best so far\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_model = model\n",
        "\n",
        "print(\"Hyperparameter tuning completed.\")\n",
        "print(f\"Best test accuracy: {best_accuracy}\")\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('best_ghostnet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "Lt7KeIRHqe5x",
        "outputId": "4450fea1-aa47-48f6-d5bd-d5e92409b4cc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best model\n",
        "best_model = load_model('best_ghostnet_model.h5')\n",
        "\n",
        "# Predict on the test dataset\n",
        "y_pred = np.argmax(best_model.predict(test_dataset), axis=-1)\n",
        "\n",
        "# Get true labels\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = np.trace(cm) / np.sum(cm)\n",
        "precision = cm[1, 1] / np.sum(cm[:, 1])\n",
        "recall = cm[1, 1] / np.sum(cm[1, :])\n",
        "sensitivity = recall\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "\n",
        "# Generate a heatmap for the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Tuberculosis\"], yticklabels=[\"Normal\", \"Tuberculosis\"])\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Tuberculosis\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "194LhOZQzc2e"
      },
      "outputs": [],
      "source": [
        "!apt update"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
